1.HDFS写数据流程
    1)客户端切分文件并发起请求,namenode检查请求的合法性(客户端文件是否存在,服务端是否已有同名文件)
    2)如果请求合法,namenode通知datanode汇报存储状态,负载均衡选出可用的datanode,并将结果返回给客户端
    3)客户端得到datanode的地址列表,就近原则挑选地址,以package的形式逐步传输文件的第一个块
    4)第一个datanode得到块文件和地址列表,优先选择不同机架的datanote,然后转发块文件的备份
    5)第二个datanode得到块文件和地址列表,优先选择相同机架的datanode,继续转发备份
    6)客户端发送第二个块文件,重复以上步骤,直至文件发送完成
    7)文件发送完成后,此次存储的事务完成.namenode接到通知,在目录树上记录新文件
    8)datanode定时汇报的时候,namenode才会检查每一次备份是否都已经完成
    
2.副本放置策略
    1)客户端得到datanode的地址列表,就近原则挑选地址,以package的形式逐步传输文件的第一个块
    2)第一个datanode得到块文件和地址列表,优先选择不同机架的datanote,然后转发块文件的备份
    3)第二个datanode得到块文件和地址列表,优先选择相同机架的datanode,继续转发备份
    
3.namenode启动过程
    1)镜像文件加载到内存
    2)日志文件加载到内存
    3)datanode汇报自己的存储情况
    
4.什么情况下会进入安全模式.安全模式的解决办法
    1)hdfs刚启动时会有30秒的默认安全模式
    2)datanode的存活数量低于阈值时(默认为0)
    3)所存储文件的丢失率超过阈值时(默认为0.999f)
    解决:1)限时的安全模式可以等待自动退出
         2)阈值异常导致的安全模式可以调高阈值
         3)也可以解决异常,比如成功重启datanode
         4)shell命令强行退出安全模式
         5)重新格式化namenode
         
5.checkpoint过程及作用
    过程:1)secondary namenode通知准备开始checkpoint
         2)namenode新建一个日志继续写入,以方便secondary整理之前的日志文件
         3)secondary namenode获取到这段时间产生的镜像和日志,并对镜像和日志进行整理汇总
         4)整理后的日志和镜像被回传给namenode,namenode做进一步整理,以备下次重启时加载
    作用:1)分担namenode的工作
         2)备份镜像和日志
         
6.namenode的工作职责
    namenode:1)处理客户端的文件存取请求
             2)维护并管理元数据
             3)负载均衡的管理datanode的存储内容
             4)监控datanode的工作状态
             
7.datanode的工作职责
    datanode:1)和namenode汇报自己的工作状态
             2)根据namenode的命令存储数据块
             3)管道式备份文件副本
             
8.datanode宕机后，集群能否立即将宕机的datanode下线，datanode下线后，集群将进行什么工作。
    集群不能立即将宕机的datanode下线,而是:
    1)心跳检测发现此datanode超时
    2)默认等待10min30s确认datanode异常
    3)将此datenode标记为dead
    4)下一次report时,namenode检测到备份文件的缺失,负载均衡的将缺失的文件重新备份到别的datanode
             
9.将一个集群重新格式化namenode后，使用start-dfs.sh启动集群，datanode能启动起来么？为什么？
    datandoe无法启动,或者启动后自动关闭
    因为集群id发生改变
    
10.HDFS高可用原理
    对应着可能出现的问题,有相应的高可用策略
    1)文件完整性
        .定期校验
        .冗余备份
    2)节点故障(硬件或网络)
        .心跳机制
        .机架/集群
    3)namenode故障
        .journalnode:镜像和日志的备份
        .secondary namenode 或 standbynamenode
    4)其他
        .安全模式
        .快照机制
        .回收站
             
11.zookeeper的应用场景
    1)实时改变配置文件
    2)分布式锁
    3)动态上下线(查看在线人数)

12.阐述zookeeper分布式锁的实现原理
    1)创建一个锁的永久节点
    2)进程在永久节点上创建一个临时节点,并递增的生成id
    3)id最小的进程可以执行,执行完成后释放执行权
    4)每个进程监控自己的前一个id,等待锁的释放
    
13.ResourceManager的工作职责，NodeManager的工作职责
    ResourceManager:计算资源的调度(cpu,内存等);
    NodeManager:监控资源使用情况,控制计算的具体内容
    
14、说说你对分布式思想的理解
    分布式文件系统就是由网路通讯连接起来的,可以共同协调完成任务的一组计算机
    对高承载量的需求是分布式系统存在的原因,该系统可以使用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务
    它可以对数据进行分块和分片以并发的执行计算任务,从而提高计算效率
    但也存在一些问题,比如常见的网络故障和节点故障
    
15、离线分析项目的处理流程
    1)数据获取
    2)预处理
    3)存入hive
    4)ETL
    5)报表统计
    6)存入sql
    7)数据可视化
    
16、HDFS为什么不适合存储小文件?
    1)hdfs系统中,文件的储存会在namenode内存中生成对应的元数据,每个约150b
    大量的小文件会给namenode带来内存压力
    2)hdfs默认的块文件大小是128M,即使存储小文件,也会分配128M的块文件,浪费了存储空间

17、分片的计算规则?
    Math.max(minSize, Math.min(maxSize, blockSize));
    
18、如何调整maptask的并行度？
    1)数据的分片决定了maptask的并行度,因此可以调整minSize, maxSize, blockSize
    2)改变数据总量也可以影响maptask的并行度
    
19、如何调整reducetask的并行度?
    Reducetask的数量可以直接手动设置：job.setNumReduceTasks(4);

20、分片信息都包含哪儿些内容
    1)起始偏移量
    2)分片大小
    3)分片数据所在的块的信息
    4)块所在的主机列表
    
21、简述下MR程序的执行全流程（可画图）
    1)MRAppMaster先启动，启动之后会计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程
    2)maptask进程启动之后，根据给定的数据切片范围进行数据处理
    3)MRAppMaster监控到所有maptask进程任务完成之后,会根据客户指定的参数启动相应数量的reducetask进程，并告知reducetask进程要处理的数据范围（数据分区）
    4)Reducetask获取到maptask输出结果文件，在本地进行重新归并排序,然后按照相同key分组
    5)依据reduce方法进行逻辑运算,最终将结果数据输出到外部存储

22、MR的shuffle流程（可画图）
    1)maptask收集我们的map()方法输出的kv对，放到内存缓冲区中
    2)从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件
    3)多个溢出文件会被合并成大的溢出文件
    4)在溢出过程中，及合并的过程中，都要调用partitoner进行分组和针对key进行排序
    5)reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据
    6)reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）
    7)合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）

23、MR中可干预的组件
    1)InputStream,输入流的选择
    2)分片大小
    3)分组方式(可自定义分组方法)
    4)reduce的数量
    5)OutputStream

24、分块和分片的区别,分块的好处。
    区别:分块是在数据存储阶段,由提交存储申请的客户端完成的,对文件的物理切分
    分片是MR程序运行时,MRappMaster对数据进行的逻辑切分
    好处: 1)分块降低了大型文件的存储对配置的要求
          2)分块可以方便的实现文件的并发读取





    
             
             